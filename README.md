# AI Mentoring Program

<p> This repository contains all training materials used during 8 weeks workshop supported by Prof Ajit Joakar and his team.

### Core team
- Ajit Jaokar - Course Director - Artificial Intelligence - Cloud and Edge Implementations University of Oxford
- Ayse Mutlu - Part of core team leading all development - Artificial Intelligence - Cloud and Edge Implementations University of Oxford
- Marina Fernandez - Part of core team leading architecture / maths - Artificial Intelligence - Cloud and Edge Implementations University of Oxford
- Kaouter Karboub - PhD Artificial Intelligence - France 

### Supported by

- Alexa Mc Mahon
- Aditya Jaokar
- Aaditya Bhaskaran
- Malhar Bhide
</p>
<hr>

## Week 1 - Introducing the core concepts

<p> Introduce the core concepts in developing and building a machine learning model, including:

- an overview of machine learning and types of machine learning
- an introduction of two main problem types: regression and classification in machine learning
- an introduction of the key machine learning libraries in python
- define machine learning workflow
- explain methods and techniques to build and train a machine learning model (such as data exploration; feature selection, feature engineering , preprocessing (outliers, normalise, missing values), model selection and evaluation)
<hr>

##Week 2:  Hands On exercises
<p>
- Exercise 2.1 - Boston House Prices prediction</p>

<p>To predict the Boston house prices based on several environmental, economic, demographic, and societal features using the Boston House dataset.<br></p> 
<p>Firstly we do data exploration and data processing. We continue to build a regression model(Support Vector machines for Regression) and evaluate the performance of the model. <br></p>
<p>
- Exercise 2.2 - Breast Cancer classification<br></p>
To create a classification model (mainly Support vector Classification) that predicts if the cancer diagnosis is benign or malignant based on several features.
<hr>

##Week 3 - Model Selection and Evaluation

Explain model selection and evaluation, including:
- An overview of model selection and model evaluation
- What are regression and classification evaluation metrics for measuring the performance of this trained model and explain when to choose these metrics
- An overview of cross validation
- An overview of ensemble methods
- An overview of hyperparameter tuning (such as GridSearchCV and RandomizedSearchCV)
<hr>

##Week 4 - Feature Engineering 

To cover feature engineering.
<hr>

##Week 5 - Building a Deep Learning model

To build a deep learning model in Keras, including:<br>
- Overview of a deep learning; MLP, CNN, SLP, VGG16, ResNet models
- Overview of Keras Model API: the sequential and the functional API
- Steps to define and train a model in Keras
- Explain how to improve a baseline model: adding hidden layers, dropout layer, changing optimizer, epochs, batch sizes, using SGD
- Types of layer; convolutional layer, pooling layer, max layer, fully connected layer

<hr>

##Week 6: Hands on Exercises
<p>
- Exercise 6.1: Classification FM without dimensionality.<br></p>

<p>
The project consists of a main task which is to classify items in the Fashion MNIST dataset successfully. </p> 
The implementation course is divided into two main parts: <br>
<p>- One which we will be doing just for once . We won’t need to rewrite the code for it every time we run the whole code. </p>  
<p>- The second part, which will contain the different models we will be using in this project mainly: Convolutional Neural Networks (CNN), Multi-Layer Perceptron (MLP), Single Layer Perceptron (SLP), VGG16, ResNet, Gaussian Mixture Model and Clustering more specifically we are going to use K-means Clustering techniques. To have more fun! We will apply these models on processed data before and after applying Principal Component Analysis (PCA).
<hr>

##Week 7- Where and when to use PCA

The aim of this week is to decide where and when to use PCA, including:
- An overview of Principal Component Analysis<br>
- Explain how to apply PCA; data standardisation, create a covariance matrix,eigen decomposition, feature transformation, 
<hr>

##Week 8 - Classification FM with dimensionality

Exercise: Classification FM with dimensionality
The project consists of a main task which is to classify items in the Fashion MNIST dataset successfully.  We will divide the implementation course into two main parts, one which we will be doing just for once and we won’t need to rewrite the code for it every time we run the whole code. The second part, which will contain the different models we will be using in this project mainly: Convolutional Neural Networks (CNN), Multi-Layer Perceptron (MLP), Single Layer Perceptron (SLP), VGG16, ResNet, Gaussian Mixture Model and Clustering more specifically we are going to use K-means Clustering techniques. To have more fun! We will apply these models on processed data before and after applying Principal Component Analysis (PCA).
<hr>